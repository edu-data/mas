"""
GAIM Lab - RAG ì§€ì‹ ê¸°ë°˜ ì‹œìŠ¤í…œ (ê²½ëŸ‰ ë²„ì „)
Gemini Embedding APIë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ êµìœ¡í•™ ë¬¸ì„œ ê¸°ë°˜ í”¼ë“œë°± ê°•í™”
ChromaDB ì—†ì´ ì¸ë©”ëª¨ë¦¬ ë²¡í„° ê²€ìƒ‰ êµ¬í˜„
"""

import os
import json
import numpy as np
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from datetime import datetime

try:
    import google.generativeai as genai
    HAS_GENAI = True
except ImportError:
    HAS_GENAI = False
    print("Warning: google-generativeai not installed. Run: pip install google-generativeai")


class EducationKnowledgeBase:
    """êµìœ¡í•™ ì§€ì‹ ê¸°ë°˜ ê²½ëŸ‰ RAG ì‹œìŠ¤í…œ
    
    7ì°¨ì› í‰ê°€ ê¸°ì¤€ ë° êµìœ¡í•™ ì´ë¡ ì„ ë²¡í„°í™”í•˜ì—¬
    ìˆ˜ì—… ë¶„ì„ í”¼ë“œë°±ì— ì´ë¡ ì  ê·¼ê±°ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    
    ChromaDB ì—†ì´ ì¸ë©”ëª¨ë¦¬ ë²¡í„° ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    
    # ì°¨ì› ì´ë¦„ê³¼ íŒŒì¼ëª… ë§¤í•‘
    DIMENSION_FILES = {
        "ìˆ˜ì—… ì „ë¬¸ì„±": "01_ìˆ˜ì—…ì „ë¬¸ì„±.md",
        "êµìˆ˜í•™ìŠµ ë°©ë²•": "02_êµìˆ˜í•™ìŠµë°©ë²•.md",
        "íŒì„œ ë° ì–¸ì–´": "03_íŒì„œ_ì–¸ì–´.md",
        "ìˆ˜ì—… íƒœë„": "04_ìˆ˜ì—…íƒœë„.md",
        "í•™ìƒ ì°¸ì—¬": "05_í•™ìƒì°¸ì—¬.md",
        "ì‹œê°„ ë°°ë¶„": "06_ì‹œê°„ë°°ë¶„.md",
        "ì°½ì˜ì„±": "07_ì°½ì˜ì„±.md"
    }
    
    def __init__(self, knowledge_dir: str = None, cache_file: str = None):
        """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            knowledge_dir: êµìœ¡í•™ ë¬¸ì„œ í´ë” ê²½ë¡œ
            cache_file: ì„ë² ë”© ìºì‹œ íŒŒì¼ ê²½ë¡œ
        """
        self.knowledge_dir = Path(knowledge_dir) if knowledge_dir else Path(__file__).parent / "knowledge"
        self.cache_file = Path(cache_file) if cache_file else Path(__file__).parent / "embeddings_cache.json"
        
        self.documents: List[Dict] = []  # {"content": str, "metadata": dict, "embedding": list}
        self.is_initialized = False
        
        if HAS_GENAI:
            self._initialize()
    
    def _initialize(self):
        """ì„ë² ë”© ì´ˆê¸°í™” ë° ë¬¸ì„œ ë¡œë“œ"""
        try:
            api_key = os.getenv("GOOGLE_API_KEY")
            if not api_key:
                print("Warning: GOOGLE_API_KEY not set. RAG features disabled.")
                return
            
            genai.configure(api_key=api_key)
            
            # ìºì‹œëœ ì„ë² ë”© ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„±
            if self.cache_file.exists():
                self._load_cache()
            else:
                self._build_embeddings()
            
            self.is_initialized = True
            print(f"RAG initialized with {len(self.documents)} document chunks")
            
        except Exception as e:
            print(f"RAG initialization error: {e}")
            self.is_initialized = False
    
    def _load_documents(self) -> List[Dict]:
        """êµìœ¡í•™ ë¬¸ì„œ ë¡œë“œ ë° ì²­í‚¹"""
        documents = []
        
        # dimensions í´ë” ë¬¸ì„œ ë¡œë“œ
        dimensions_dir = self.knowledge_dir / "dimensions"
        if dimensions_dir.exists():
            for file_path in dimensions_dir.glob("*.md"):
                try:
                    content = file_path.read_text(encoding="utf-8")
                    
                    # ì„¹ì…˜ë³„ë¡œ ì²­í‚¹
                    chunks = self._chunk_document(content)
                    for i, chunk in enumerate(chunks):
                        documents.append({
                            "content": chunk,
                            "metadata": {
                                "source": str(file_path.name),
                                "type": "dimension",
                                "chunk_index": i,
                                "dimension_name": file_path.stem.split("_", 1)[-1] if "_" in file_path.stem else file_path.stem
                            }
                        })
                except Exception as e:
                    print(f"Error loading {file_path}: {e}")
        
        print(f"Loaded {len(documents)} document chunks")
        return documents
    
    def _chunk_document(self, content: str, max_chunk_size: int = 1000) -> List[str]:
        """ë¬¸ì„œë¥¼ ì„¹ì…˜ ê¸°ë°˜ìœ¼ë¡œ ì²­í‚¹"""
        chunks = []
        
        # ## ë˜ëŠ” ### ìœ¼ë¡œ ë¶„í• 
        sections = content.split("\n## ")
        for section in sections:
            if len(section) > max_chunk_size:
                # ì¶”ê°€ ë¶„í• 
                sub_sections = section.split("\n### ")
                for sub in sub_sections:
                    if sub.strip():
                        chunks.append(sub.strip()[:max_chunk_size])
            elif section.strip():
                chunks.append(section.strip())
        
        return chunks if chunks else [content[:max_chunk_size]]
    
    def _get_embedding(self, text: str) -> List[float]:
        """Gemini Embedding APIë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        try:
            result = genai.embed_content(
                model="models/embedding-001",
                content=text,
                task_type="retrieval_document"
            )
            return result['embedding']
        except Exception as e:
            print(f"Embedding error: {e}")
            return []
    
    def _get_query_embedding(self, text: str) -> List[float]:
        """ì¿¼ë¦¬ìš© ì„ë² ë”© ìƒì„±"""
        try:
            result = genai.embed_content(
                model="models/embedding-001",
                content=text,
                task_type="retrieval_query"
            )
            return result['embedding']
        except Exception as e:
            print(f"Query embedding error: {e}")
            return []
    
    def _build_embeddings(self):
        """ëª¨ë“  ë¬¸ì„œì— ëŒ€í•´ ì„ë² ë”© ìƒì„± ë° ìºì‹œ"""
        raw_docs = self._load_documents()
        
        for doc in raw_docs:
            embedding = self._get_embedding(doc["content"])
            if embedding:
                doc["embedding"] = embedding
                self.documents.append(doc)
        
        # ìºì‹œì— ì €ì¥
        self._save_cache()
        print(f"Built embeddings for {len(self.documents)} chunks")
    
    def _save_cache(self):
        """ì„ë² ë”© ìºì‹œ ì €ì¥"""
        try:
            cache_data = []
            for doc in self.documents:
                cache_data.append({
                    "content": doc["content"],
                    "metadata": doc["metadata"],
                    "embedding": doc["embedding"]
                })
            
            self.cache_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.cache_file, "w", encoding="utf-8") as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            print(f"Cache saved to {self.cache_file}")
        except Exception as e:
            print(f"Cache save error: {e}")
    
    def _load_cache(self):
        """ì„ë² ë”© ìºì‹œ ë¡œë“œ"""
        try:
            with open(self.cache_file, "r", encoding="utf-8") as f:
                self.documents = json.load(f)
            print(f"Cache loaded: {len(self.documents)} chunks")
        except Exception as e:
            print(f"Cache load error: {e}")
            self._build_embeddings()
    
    def rebuild_index(self):
        """ì¸ë±ìŠ¤ ì¬ë¹Œë“œ (ë¬¸ì„œ ë³€ê²½ ì‹œ í˜¸ì¶œ)"""
        self.documents = []
        if self.cache_file.exists():
            self.cache_file.unlink()
        self._build_embeddings()
    
    def _cosine_similarity(self, a: List[float], b: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        a = np.array(a)
        b = np.array(b)
        return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))
    
    def search(self, query: str, k: int = 3) -> List[Dict]:
        """ê´€ë ¨ êµìœ¡í•™ ë‚´ìš© ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ [{"content": str, "metadata": dict, "score": float}]
        """
        if not self.is_initialized or not self.documents:
            return []
        
        try:
            query_embedding = self._get_query_embedding(query)
            if not query_embedding:
                return []
            
            # ëª¨ë“  ë¬¸ì„œì™€ ìœ ì‚¬ë„ ê³„ì‚°
            scores = []
            for doc in self.documents:
                if "embedding" in doc:
                    score = self._cosine_similarity(query_embedding, doc["embedding"])
                    scores.append((doc, score))
            
            # ìƒìœ„ kê°œ ë°˜í™˜
            scores.sort(key=lambda x: x[1], reverse=True)
            
            return [
                {
                    "content": doc["content"],
                    "metadata": doc["metadata"],
                    "score": score
                }
                for doc, score in scores[:k]
            ]
        except Exception as e:
            print(f"Search error: {e}")
            return []
    
    def search_for_dimension(self, dimension_name: str, feedback: str, k: int = 2) -> List[Dict]:
        """íŠ¹ì • ì°¨ì›ì— ëŒ€í•œ ì´ë¡ ì  ê·¼ê±° ê²€ìƒ‰"""
        query = f"{dimension_name}: {feedback}"
        return self.search(query, k=k)
    
    def enhance_feedback(self, dimension_name: str, raw_feedback: str, score_percentage: float) -> Dict:
        """í”¼ë“œë°±ì— êµìœ¡í•™ì  ê·¼ê±° ì¶”ê°€
        
        Args:
            dimension_name: ì°¨ì› ì´ë¦„
            raw_feedback: ì›ë³¸ í”¼ë“œë°±
            score_percentage: ì ìˆ˜ í¼ì„¼í‹°ì§€ (0-100)
            
        Returns:
            {
                "original_feedback": str,
                "enhanced_feedback": str,
                "theory_references": List[str],
                "improvement_tips": List[str]
            }
        """
        if not self.is_initialized:
            return {
                "original_feedback": raw_feedback,
                "enhanced_feedback": raw_feedback,
                "theory_references": [],
                "improvement_tips": []
            }
        
        # ê´€ë ¨ ì´ë¡  ê²€ìƒ‰
        search_results = self.search_for_dimension(dimension_name, raw_feedback)
        
        theory_references = []
        improvement_tips = []
        
        for result in search_results:
            content = result["content"]
            
            # êµìœ¡í•™ì  ê·¼ê±° ì¶”ì¶œ
            if "êµìœ¡í•™ì  ê·¼ê±°" in content:
                theory_part = content.split("êµìœ¡í•™ì  ê·¼ê±°")[1].split("##")[0] if "##" in content.split("êµìœ¡í•™ì  ê·¼ê±°")[1] else content.split("êµìœ¡í•™ì  ê·¼ê±°")[1]
                theory_references.append(theory_part.strip()[:300])
            
            # ê°œì„  í”¼ë“œë°± ì¶”ì¶œ
            if "ê°œì„  í”¼ë“œë°±" in content:
                tips_part = content.split("ê°œì„  í”¼ë“œë°±")[1].split("###")[0] if "###" in content.split("ê°œì„  í”¼ë“œë°±")[1] else content.split("ê°œì„  í”¼ë“œë°±")[1]
                for line in tips_part.strip().split("\n"):
                    if line.strip().startswith("-"):
                        improvement_tips.append(line.strip().lstrip("- "))
        
        # ê°•í™”ëœ í”¼ë“œë°± ìƒì„±
        enhanced = raw_feedback
        if score_percentage < 70 and improvement_tips:
            enhanced += f"\n\nğŸ’¡ ê°œì„  ì œì•ˆ: {improvement_tips[0]}"
        
        return {
            "original_feedback": raw_feedback,
            "enhanced_feedback": enhanced,
            "theory_references": theory_references[:2],
            "improvement_tips": improvement_tips[:3]
        }
    
    def get_dimension_theory(self, dimension_name: str) -> str:
        """íŠ¹ì • ì°¨ì›ì˜ êµìœ¡í•™ì  ê·¼ê±° ë°˜í™˜"""
        results = self.search(dimension_name, k=1)
        if results:
            return results[0]["content"]
        return ""


# ì‹±ê¸€í„´ ì¸ìŠ¤í„´ìŠ¤
_knowledge_base = None

def get_knowledge_base() -> EducationKnowledgeBase:
    """ê¸€ë¡œë²Œ ì§€ì‹ ê¸°ë°˜ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _knowledge_base
    if _knowledge_base is None:
        _knowledge_base = EducationKnowledgeBase()
    return _knowledge_base


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    print("=== RAG Knowledge Base Test ===")
    kb = EducationKnowledgeBase(knowledge_dir="D:/AI/GAIM_Lab/backend/app/knowledge")
    
    if kb.is_initialized:
        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("\n[Search Test]")
        results = kb.search("í•™ìƒ ì°¸ì—¬ ìœ ë„ ë°œë¬¸ ê¸°ë²•")
        print(f"Found {len(results)} results")
        for r in results:
            print(f"  - Score: {r['score']:.3f}")
            print(f"    Content: {r['content'][:80]}...")
        
        # í”¼ë“œë°± ê°•í™” í…ŒìŠ¤íŠ¸
        print("\n[Feedback Enhancement Test]")
        enhanced = kb.enhance_feedback(
            dimension_name="í•™ìƒ ì°¸ì—¬",
            raw_feedback="ì§ˆë¬¸ì´ ë‹¨ë‹µí˜•ì— ê·¸ì³ í•™ìƒë“¤ì˜ ì‚¬ê³ ë¥¼ í™•ì¥ì‹œí‚¤ì§€ ëª»í•¨",
            score_percentage=45.0
        )
        print(f"Original: {enhanced['original_feedback']}")
        print(f"Enhanced: {enhanced['enhanced_feedback']}")
        print(f"Theory refs: {len(enhanced['theory_references'])}")
        print(f"Tips: {enhanced['improvement_tips'][:2] if enhanced['improvement_tips'] else 'None'}")
    else:
        print("RAG system not initialized. Check API key.")
