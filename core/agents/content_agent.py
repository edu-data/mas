"""
ğŸ¨ Content Agent - ìŠ¬ë¼ì´ë“œ/í™”ë©´ í’ˆì§ˆ ë¶„ì„
ë¡œì»¬ OCR(pytesseract)ê³¼ OpenCVë¥¼ í™œìš©í•œ í™”ë©´ ë¶„ì„ (API í‚¤ ë¶ˆí•„ìš”)
"""

import cv2
import numpy as np
from dataclasses import dataclass
from typing import List, Dict, Optional, Tuple
from pathlib import Path

# pytesseractëŠ” ì„ íƒì  import
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False


@dataclass
class ContentMetrics:
    """í™”ë©´/ìŠ¬ë¼ì´ë“œ ë¶„ì„ ê²°ê³¼"""
    timestamp: float
    text_density: int = 0              # ê°ì§€ëœ í…ìŠ¤íŠ¸ ê¸€ì ìˆ˜
    text_density_score: int = 5        # í…ìŠ¤íŠ¸ ë°€ë„ ì ìˆ˜ (1-10, 10=ë§¤ìš° ë§ìŒ)
    readability: str = "unknown"       # good, bad, unknown
    slide_detected: bool = False       # ìŠ¬ë¼ì´ë“œ ì˜ì—­ ê°ì§€ ì—¬ë¶€
    speaker_visible: bool = False      # ê°•ì‚¬ ì˜ìƒ ê°ì§€ ì—¬ë¶€
    speaker_overlap: bool = False      # ê°•ì‚¬ê°€ ìŠ¬ë¼ì´ë“œë¥¼ ê°€ë¦¬ëŠ”ì§€
    color_contrast: float = 0.0        # ìƒ‰ìƒ ëŒ€ë¹„ (0-1)
    brightness: float = 0.0            # í‰ê·  ë°ê¸° (0-255)
    complexity_score: float = 0.0      # í™”ë©´ ë³µì¡ë„ (0-100)


class ContentAgent:
    """
    ğŸ¨ Content Agent
    PPT/í™”ë©´ êµ¬ì„±, í…ìŠ¤íŠ¸ ë°€ë„, ê°€ë…ì„± ë¶„ì„
    (Gemini API ì—†ì´ ë¡œì»¬ ë¶„ì„)
    """
    
    def __init__(self, config: Optional[dict] = None):
        self.config = config or {
            "text_density_threshold": 150,
            "min_font_detection": 12,
            "ocr_language": "kor+eng",
        }
        
        self.results: List[ContentMetrics] = []
        
        if not TESSERACT_AVAILABLE:
            print("[!] pytesseract not installed. Text analysis will be limited.")
    
    def analyze_frame(self, frame: np.ndarray, timestamp: float) -> ContentMetrics:
        """
        ë‹¨ì¼ í”„ë ˆì„ì˜ í™”ë©´ êµ¬ì„± ë¶„ì„
        
        Args:
            frame: BGR ì´ë¯¸ì§€ (OpenCV í˜•ì‹)
            timestamp: í”„ë ˆì„ íƒ€ì„ìŠ¤íƒ¬í”„ (ì´ˆ)
            
        Returns:
            ContentMetrics ê°ì²´
        """
        metrics = ContentMetrics(timestamp=timestamp)
        
        # 1. ê¸°ë³¸ ì´ë¯¸ì§€ ì†ì„± ë¶„ì„
        self._analyze_basic_properties(frame, metrics)
        
        # 2. í™”ë©´ ì˜ì—­ ë¶„ì„ (ìŠ¬ë¼ì´ë“œ vs ê°•ì‚¬)
        self._analyze_regions(frame, metrics)
        
        # 3. í…ìŠ¤íŠ¸ ë¶„ì„ (OCR ì‚¬ìš© ê°€ëŠ¥ ì‹œ)
        if TESSERACT_AVAILABLE:
            self._analyze_text(frame, metrics)
        else:
            self._estimate_text_density(frame, metrics)
        
        # 4. í™”ë©´ ë³µì¡ë„ ë¶„ì„
        self._analyze_complexity(frame, metrics)
        
        self.results.append(metrics)
        return metrics
    
    def _analyze_basic_properties(self, frame: np.ndarray, metrics: ContentMetrics):
        """ê¸°ë³¸ ì´ë¯¸ì§€ ì†ì„± ë¶„ì„"""
        # ë°ê¸° ê³„ì‚°
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        metrics.brightness = float(np.mean(gray))
        
        # ìƒ‰ìƒ ëŒ€ë¹„ ê³„ì‚°
        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
        l_channel = lab[:, :, 0]
        metrics.color_contrast = float(np.std(l_channel) / 128)
    
    def _analyze_regions(self, frame: np.ndarray, metrics: ContentMetrics):
        """í™”ë©´ ì˜ì—­ ë¶„ì„ (ìŠ¬ë¼ì´ë“œ, ê°•ì‚¬ ì˜ì—­ ê°ì§€)"""
        height, width = frame.shape[:2]
        
        # í”„ë ˆì„ì„ ì˜ì—­ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ë¶„ì„
        # ì¼ë°˜ì ì¸ í™”ë©´ ê³µìœ  ë ˆì´ì•„ì›ƒ ê°€ì •:
        # - ìŠ¬ë¼ì´ë“œ: ì£¼ë¡œ ì¤‘ì•™~ì˜¤ë¥¸ìª½
        # - ê°•ì‚¬: ì¢Œì¸¡ í•˜ë‹¨ ë˜ëŠ” ìš°ì¸¡ ìƒë‹¨ ì‘ì€ ì˜ì—­
        
        # í™”ë©´ ê° ì˜ì—­ì˜ íŠ¹ì„± ë¶„ì„
        regions = {
            "top_left": frame[0:height//3, 0:width//3],
            "top_right": frame[0:height//3, 2*width//3:],
            "bottom_left": frame[2*height//3:, 0:width//3],
            "bottom_right": frame[2*height//3:, 2*width//3:],
            "center": frame[height//4:3*height//4, width//4:3*width//4]
        }
        
        # ì–¼êµ´ ê°ì§€ë¡œ ê°•ì‚¬ ì˜ì—­ í™•ì¸
        face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
        
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.1, 4)
        
        if len(faces) > 0:
            metrics.speaker_visible = True
            
            # ì–¼êµ´ì´ ì¤‘ì•™ì— ìˆìœ¼ë©´ ìŠ¬ë¼ì´ë“œë¥¼ ê°€ë¦´ ê°€ëŠ¥ì„±
            for (x, y, w, h) in faces:
                face_center_x = x + w // 2
                if width // 3 < face_center_x < 2 * width // 3:
                    metrics.speaker_overlap = True
                    break
        
        # ìŠ¬ë¼ì´ë“œ ê°ì§€ (í…ìŠ¤íŠ¸/ë„í˜•ì´ ìˆëŠ” ê· ì¼í•œ ë°°ê²½ ì˜ì—­)
        center_region = regions["center"]
        center_gray = cv2.cvtColor(center_region, cv2.COLOR_BGR2GRAY)
        
        # ì—£ì§€ ê°ì§€ë¡œ ì½˜í…ì¸  ì¡´ì¬ í™•ì¸
        edges = cv2.Canny(center_gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        
        # ì¼ì • ìˆ˜ì¤€ì˜ ì—£ì§€ ë°€ë„ê°€ ìˆìœ¼ë©´ ìŠ¬ë¼ì´ë“œë¡œ íŒë‹¨
        if 0.01 < edge_density < 0.3:
            metrics.slide_detected = True
    
    def _analyze_text(self, frame: np.ndarray, metrics: ContentMetrics):
        """OCRì„ í†µí•œ í…ìŠ¤íŠ¸ ë¶„ì„"""
        try:
            # ì „ì²˜ë¦¬: í…ìŠ¤íŠ¸ ì¸ì‹ë¥  í–¥ìƒ
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # ì ì‘í˜• ì´ì§„í™”
            binary = cv2.adaptiveThreshold(
                gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                cv2.THRESH_BINARY, 11, 2
            )
            
            # OCR ìˆ˜í–‰
            text = pytesseract.image_to_string(
                binary, 
                lang=self.config["ocr_language"]
            )
            
            # í…ìŠ¤íŠ¸ ë°€ë„ ê³„ì‚°
            # ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ê¸€ì ìˆ˜
            clean_text = ''.join(c for c in text if c.isalnum())
            metrics.text_density = len(clean_text)
            
            # í…ìŠ¤íŠ¸ ë°€ë„ ì ìˆ˜ (1-10)
            threshold = self.config["text_density_threshold"]
            density_ratio = metrics.text_density / threshold
            metrics.text_density_score = min(10, max(1, int(density_ratio * 5) + 1))
            
            # ê°€ë…ì„± íŒë‹¨
            if metrics.text_density > threshold * 1.5:
                metrics.readability = "bad"  # í…ìŠ¤íŠ¸ ê³¼ë‹¤
            elif metrics.text_density < 10:
                metrics.readability = "good"  # ì ì ˆí•˜ê±°ë‚˜ ì´ë¯¸ì§€ ìœ„ì£¼
            else:
                metrics.readability = "good"
                
        except Exception as e:
            print(f"[!] OCR Error: {e}")
            self._estimate_text_density(frame, metrics)
    
    def _estimate_text_density(self, frame: np.ndarray, metrics: ContentMetrics):
        """OCR ì—†ì´ í…ìŠ¤íŠ¸ ë°€ë„ ì¶”ì • (ì—£ì§€ ê¸°ë°˜)"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ (MSER ì•Œê³ ë¦¬ì¦˜)
        mser = cv2.MSER_create()
        regions, _ = mser.detectRegions(gray)
        
        # í…ìŠ¤íŠ¸ë¡œ ì¶”ì •ë˜ëŠ” ì˜ì—­ ìˆ˜ë¡œ ë°€ë„ ì¶”ì •
        estimated_chars = len(regions) // 3  # ëŒ€ëµì ì¸ ê¸€ì ìˆ˜ ì¶”ì •
        metrics.text_density = estimated_chars
        
        # ì ìˆ˜ ê³„ì‚°
        density_ratio = estimated_chars / self.config["text_density_threshold"]
        metrics.text_density_score = min(10, max(1, int(density_ratio * 5) + 1))
        
        if estimated_chars > self.config["text_density_threshold"]:
            metrics.readability = "bad"
        else:
            metrics.readability = "unknown"
    
    def _analyze_complexity(self, frame: np.ndarray, metrics: ContentMetrics):
        """í™”ë©´ ë³µì¡ë„ ë¶„ì„"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # Laplacian varianceë¡œ ë³µì¡ë„ ì¸¡ì •
        laplacian = cv2.Laplacian(gray, cv2.CV_64F)
        variance = laplacian.var()
        
        # ì •ê·œí™” (0-100)
        metrics.complexity_score = min(100, variance / 50)
    
    def get_summary(self) -> Dict:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½"""
        if not self.results:
            return {"error": "ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤"}
        
        total = len(self.results)
        
        return {
            "total_frames_analyzed": total,
            "avg_text_density": np.mean([r.text_density for r in self.results]),
            "avg_text_density_score": np.mean([r.text_density_score for r in self.results]),
            "high_density_ratio": sum(1 for r in self.results if r.text_density_score >= 7) / total,
            "slide_detection_ratio": sum(1 for r in self.results if r.slide_detected) / total,
            "speaker_visible_ratio": sum(1 for r in self.results if r.speaker_visible) / total,
            "speaker_overlap_ratio": sum(1 for r in self.results if r.speaker_overlap) / total,
            "avg_brightness": np.mean([r.brightness for r in self.results]),
            "avg_complexity": np.mean([r.complexity_score for r in self.results]),
            "warnings": self._get_warnings()
        }
    
    def _get_warnings(self) -> List[str]:
        """ê²½ê³  ë©”ì‹œì§€ ìƒì„±"""
        if not self.results:
            return []
        
        warnings = []
        total = len(self.results)
        
        # Calculate values directly to avoid recursion
        high_density_ratio = sum(1 for r in self.results if r.text_density_score >= 7) / total
        speaker_overlap_ratio = sum(1 for r in self.results if r.speaker_overlap) / total
        avg_brightness = np.mean([r.brightness for r in self.results])
        
        if high_density_ratio > 0.3:
            warnings.append("[!] High text density detected in over 30% of frames")
        
        if speaker_overlap_ratio > 0.2:
            warnings.append("[!] Speaker frequently overlaps slide content")
        
        if avg_brightness < 80:
            warnings.append("[!] Screen is generally too dark")
        elif avg_brightness > 220:
            warnings.append("[!] Screen is generally too bright")
        
        return warnings
    
    def get_timeline(self) -> List[Dict]:
        """ì‹œê°„ë³„ ë¶„ì„ ê²°ê³¼"""
        return [
            {
                "timestamp": r.timestamp,
                "text_density_score": r.text_density_score,
                "readability": r.readability,
                "slide_detected": r.slide_detected,
                "speaker_overlap": r.speaker_overlap
            }
            for r in self.results
        ]
    
    def find_high_density_frames(self) -> List[float]:
        """í…ìŠ¤íŠ¸ ë°€ë„ê°€ ë†’ì€ í”„ë ˆì„ íƒ€ì„ìŠ¤íƒ¬í”„"""
        return [
            r.timestamp 
            for r in self.results 
            if r.text_density_score >= 7
        ]
    
    def reset(self):
        """ë¶„ì„ ê²°ê³¼ ì´ˆê¸°í™”"""
        self.results = []
