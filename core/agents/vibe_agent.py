"""
ğŸ”Š Vibe Agent - ìŒì„± í”„ë¡œì†Œë””(ìš´ìœ¨) ë¶„ì„
librosaë¥¼ í™œìš©í•œ í†¤, ì†ë„, íœ´ì§€ê¸° ë¶„ì„ (ë‚´ìš©ì´ ì•„ë‹Œ ì†Œë¦¬ì˜ íŒŒí˜• ë¶„ì„)
"""

import numpy as np
import librosa
from dataclasses import dataclass
from typing import List, Dict, Optional, Tuple
from pathlib import Path


@dataclass
class VibeMetrics:
    """ìŒì„± í”„ë¡œì†Œë”” ë¶„ì„ ê²°ê³¼"""
    segment_start: float           # ì„¸ê·¸ë¨¼íŠ¸ ì‹œì‘ ì‹œê°„ (ì´ˆ)
    segment_end: float             # ì„¸ê·¸ë¨¼íŠ¸ ì¢…ë£Œ ì‹œê°„ (ì´ˆ)
    pitch_mean: float = 0.0        # í‰ê·  í”¼ì¹˜ (Hz)
    pitch_std: float = 0.0         # í”¼ì¹˜ í‘œì¤€í¸ì°¨ (ë‹¤ì–‘ì„±)
    energy_mean: float = 0.0       # í‰ê·  ì—ë„ˆì§€ (RMS)
    energy_std: float = 0.0        # ì—ë„ˆì§€ í‘œì¤€í¸ì°¨
    speaking_rate: float = 0.0     # ë§í•˜ê¸° ì†ë„ ì¶”ì •
    silence_ratio: float = 0.0     # ì¹¨ë¬µ ë¹„ìœ¨
    is_monotone: bool = False      # ë‹¨ì¡°ë¡œì›€ ì—¬ë¶€
    energy_level: str = "normal"   # low, normal, high


class VibeAgent:
    """
    ğŸ”Š Vibe Agent
    ëª©ì†Œë¦¬ì˜ í†¤, ë¹ ë¥´ê¸°, íœ´ì§€ê¸° ë“± ìŒì„± í”„ë¡œì†Œë””(ìš´ìœ¨) ë¶„ì„
    """
    
    def __init__(self, config: Optional[dict] = None):
        self.config = config or {
            "sample_rate": 22050,
            "monotone_threshold": 15,
            "silence_db": 20,
            "ideal_silence_ratio": (0.1, 0.3),
            "segment_duration": 10.0  # ë¶„ì„ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ (ì´ˆ)
        }
        
        self.results: List[VibeMetrics] = []
        self.audio_data: Optional[np.ndarray] = None
        self.sr: int = self.config["sample_rate"]
    
    def load_audio(self, audio_path: Path) -> None:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ"""
        print(f"ğŸ”Š ì˜¤ë””ì˜¤ ë¡œë“œ ì¤‘: {audio_path}")
        self.audio_data, self.sr = librosa.load(
            str(audio_path), 
            sr=self.config["sample_rate"]
        )
        print(f"âœ… ë¡œë“œ ì™„ë£Œ: {len(self.audio_data)/self.sr:.1f}ì´ˆ")
    
    def analyze_full(self, audio_path: Optional[Path] = None) -> List[VibeMetrics]:
        """
        ì „ì²´ ì˜¤ë””ì˜¤ ë¶„ì„ (ì„¸ê·¸ë¨¼íŠ¸ ë‹¨ìœ„)
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ì´ë¯¸ ë¡œë“œëœ ë°ì´í„° ì‚¬ìš©)
            
        Returns:
            VibeMetrics ë¦¬ìŠ¤íŠ¸
        """
        if audio_path:
            self.load_audio(audio_path)
        
        if self.audio_data is None:
            raise ValueError("ì˜¤ë””ì˜¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        duration = len(self.audio_data) / self.sr
        segment_duration = self.config["segment_duration"]
        
        print(f"ğŸ“Š í”„ë¡œì†Œë”” ë¶„ì„ ì‹œì‘ (ì´ {duration:.1f}ì´ˆ, ì„¸ê·¸ë¨¼íŠ¸: {segment_duration}ì´ˆ)")
        
        self.results = []
        current_time = 0
        
        while current_time < duration:
            end_time = min(current_time + segment_duration, duration)
            metrics = self.analyze_segment(current_time, end_time)
            self.results.append(metrics)
            current_time = end_time
        
        print(f"âœ… í”„ë¡œì†Œë”” ë¶„ì„ ì™„ë£Œ: {len(self.results)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        return self.results
    
    def analyze_segment(self, start_time: float, end_time: float) -> VibeMetrics:
        """
        íŠ¹ì • êµ¬ê°„ì˜ ìŒì„± í”„ë¡œì†Œë”” ë¶„ì„
        
        Args:
            start_time: ì‹œì‘ ì‹œê°„ (ì´ˆ)
            end_time: ì¢…ë£Œ ì‹œê°„ (ì´ˆ)
            
        Returns:
            VibeMetrics ê°ì²´
        """
        # ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ
        start_sample = int(start_time * self.sr)
        end_sample = int(end_time * self.sr)
        segment = self.audio_data[start_sample:end_sample]
        
        if len(segment) == 0:
            return VibeMetrics(segment_start=start_time, segment_end=end_time)
        
        metrics = VibeMetrics(segment_start=start_time, segment_end=end_time)
        
        # 1. í”¼ì¹˜ ë¶„ì„
        self._analyze_pitch(segment, metrics)
        
        # 2. ì—ë„ˆì§€ ë¶„ì„
        self._analyze_energy(segment, metrics)
        
        # 3. ì¹¨ë¬µ ë¶„ì„
        self._analyze_silence(segment, metrics)
        
        # 4. ë‹¨ì¡°ë¡œì›€ íŒì •
        self._check_monotone(metrics)
        
        return metrics
    
    def _analyze_pitch(self, segment: np.ndarray, metrics: VibeMetrics):
        """í”¼ì¹˜(ìŒë†’ì´) ë¶„ì„"""
        # librosaì˜ piptrackìœ¼ë¡œ í”¼ì¹˜ ì¶”ì¶œ
        pitches, magnitudes = librosa.piptrack(
            y=segment, 
            sr=self.sr,
            fmin=50,   # ìµœì†Œ ì£¼íŒŒìˆ˜ (ì¼ë°˜ ìŒì„±)
            fmax=500   # ìµœëŒ€ ì£¼íŒŒìˆ˜
        )
        
        # ìœ íš¨í•œ í”¼ì¹˜ë§Œ ì¶”ì¶œ
        pitch_values = []
        for t in range(pitches.shape[1]):
            index = magnitudes[:, t].argmax()
            pitch = pitches[index, t]
            if pitch > 0:
                pitch_values.append(pitch)
        
        if pitch_values:
            metrics.pitch_mean = np.mean(pitch_values)
            metrics.pitch_std = np.std(pitch_values)
    
    def _analyze_energy(self, segment: np.ndarray, metrics: VibeMetrics):
        """ì—ë„ˆì§€(ìŒëŸ‰) ë¶„ì„"""
        # RMS ì—ë„ˆì§€ ê³„ì‚°
        rms = librosa.feature.rms(y=segment)[0]
        
        metrics.energy_mean = float(np.mean(rms))
        metrics.energy_std = float(np.std(rms))
        
        # ì—ë„ˆì§€ ë ˆë²¨ ë¶„ë¥˜
        if metrics.energy_mean < 0.02:
            metrics.energy_level = "low"
        elif metrics.energy_mean > 0.1:
            metrics.energy_level = "high"
        else:
            metrics.energy_level = "normal"
    
    def _analyze_silence(self, segment: np.ndarray, metrics: VibeMetrics):
        """ì¹¨ë¬µ(íœ´ì§€ê¸°) ë¶„ì„"""
        # ë¹„ì¹¨ë¬µ êµ¬ê°„ íƒì§€
        intervals = librosa.effects.split(
            segment, 
            top_db=self.config["silence_db"]
        )
        
        # ë§í•˜ëŠ” êµ¬ê°„ì˜ ì´ ê¸¸ì´
        speaking_samples = sum(end - start for start, end in intervals)
        total_samples = len(segment)
        
        metrics.silence_ratio = 1 - (speaking_samples / total_samples)
        
        # ë§í•˜ê¸° ì†ë„ ì¶”ì • (ë¹„ì¹¨ë¬µ êµ¬ê°„ ë‹¹ í‰ê·  ê¸¸ì´)
        if len(intervals) > 0:
            avg_speaking_duration = speaking_samples / len(intervals) / self.sr
            metrics.speaking_rate = 1 / avg_speaking_duration if avg_speaking_duration > 0 else 0
    
    def _check_monotone(self, metrics: VibeMetrics):
        """ë‹¨ì¡°ë¡œì›€ íŒì •"""
        threshold = self.config["monotone_threshold"]
        
        # í”¼ì¹˜ í‘œì¤€í¸ì°¨ê°€ ë‚®ìœ¼ë©´ ë‹¨ì¡°ë¡œì›€
        if metrics.pitch_std < threshold:
            metrics.is_monotone = True
        
        # ì—ë„ˆì§€ ë³€í™”ë„ ê³ ë ¤
        if metrics.energy_std < 0.01:
            metrics.is_monotone = True
    
    def get_summary(self) -> Dict:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½"""
        if not self.results:
            return {"error": "ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤"}
        
        total = len(self.results)
        
        return {
            "total_segments": total,
            "avg_pitch": np.mean([r.pitch_mean for r in self.results if r.pitch_mean > 0]),
            "pitch_variety": np.mean([r.pitch_std for r in self.results]),
            "avg_energy": np.mean([r.energy_mean for r in self.results]),
            "energy_variety": np.mean([r.energy_std for r in self.results]),
            "avg_silence_ratio": np.mean([r.silence_ratio for r in self.results]),
            "monotone_ratio": sum(1 for r in self.results if r.is_monotone) / total,
            "energy_distribution": self._get_energy_distribution(),
            "warnings": self._get_warnings()
        }
    
    def _get_energy_distribution(self) -> Dict[str, float]:
        """ì—ë„ˆì§€ ë ˆë²¨ ë¶„í¬"""
        if not self.results:
            return {}
        
        levels = [r.energy_level for r in self.results]
        total = len(levels)
        
        return {
            "low": levels.count("low") / total,
            "normal": levels.count("normal") / total,
            "high": levels.count("high") / total
        }
    
    def _get_warnings(self) -> List[str]:
        """ê²½ê³  ë©”ì‹œì§€ ìƒì„±"""
        if not self.results:
            return []
        
        warnings = []
        ideal_min, ideal_max = self.config["ideal_silence_ratio"]
        
        # Calculate values directly to avoid recursion
        total = len(self.results)
        monotone_ratio = sum(1 for r in self.results if r.is_monotone) / total
        avg_silence_ratio = np.mean([r.silence_ratio for r in self.results])
        
        if monotone_ratio > 0.5:
            warnings.append("[!] Over 50% of segments have monotone tone")
        
        if avg_silence_ratio > ideal_max:
            warnings.append("[!] High silence ratio (hesitation or lack of preparation)")
        elif avg_silence_ratio < ideal_min:
            warnings.append("[!] Speaking too fast without pauses")
        
        return warnings
    
    def get_timeline(self) -> List[Dict]:
        """ì‹œê°„ë³„ ë¶„ì„ ê²°ê³¼"""
        return [
            {
                "start": r.segment_start,
                "end": r.segment_end,
                "pitch_std": r.pitch_std,
                "energy_mean": r.energy_mean,
                "silence_ratio": r.silence_ratio,
                "is_monotone": r.is_monotone
            }
            for r in self.results
        ]
    
    def find_monotone_segments(self) -> List[Tuple[float, float]]:
        """ë‹¨ì¡°ë¡œìš´ êµ¬ê°„ ì°¾ê¸°"""
        return [
            (r.segment_start, r.segment_end)
            for r in self.results
            if r.is_monotone
        ]
    
    def reset(self):
        """ë¶„ì„ ê²°ê³¼ ì´ˆê¸°í™”"""
        self.results = []
        self.audio_data = None
