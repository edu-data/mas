"""
ğŸ“ Text Analyzer - ê°•ì˜ í…ìŠ¤íŠ¸ ë¶„ì„ ëª¨ë“ˆ
faster-whisper STT + 'ì¢‹ì€ ìˆ˜ì—…' ê´€ì  í…ìŠ¤íŠ¸ ë¶„ì„

ë¶„ì„ ì§€í‘œ:
1. êµìˆ˜ í™”ë²•: ìš©ì–´ ì„¤ëª…, ì˜ˆì‹œ ì‚¬ìš©, ê°•ì¡° í‘œí˜„
2. í•™ìŠµì ì°¸ì—¬: ì§ˆë¬¸ ê¸°ë²•, ì°¸ì—¬ ìœ ë„
3. êµ¬ì¡°í™”: ë„ì…, ì „í™˜, ìš”ì•½ í‘œí˜„
4. í‰ê°€ ë° ì •ë¦¬: ì´í•´ ì ê²€, ë§ˆë¬´ë¦¬
"""

import re
import os
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, field

# whisper ì¡°ê±´ë¶€ ì„í¬íŠ¸ (openai-whisper)
try:
    import whisper
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False
    print("[!] openai-whisper not available. Run: pip install openai-whisper")


@dataclass
class TextSegment:
    """í…ìŠ¤íŠ¸ ì„¸ê·¸ë¨¼íŠ¸"""
    start: float
    end: float
    text: str


@dataclass
class TextAnalysisResult:
    """í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼"""
    transcript: str                          # ì „ì²´ í…ìŠ¤íŠ¸
    segments: List[TextSegment]              # ì„¸ê·¸ë¨¼íŠ¸ë³„ í…ìŠ¤íŠ¸
    teaching_metrics: Dict                   # êµìˆ˜ í™”ë²• ì§€í‘œ
    interaction_metrics: Dict                # ìƒí˜¸ì‘ìš© ì§€í‘œ
    structure_metrics: Dict                  # êµ¬ì¡°í™” ì§€í‘œ
    quality_score: float                     # ì¢…í•© ì ìˆ˜
    word_count: int                          # ì´ ë‹¨ì–´ ìˆ˜
    duration_seconds: float                  # ë¶„ì„ëœ ì˜¤ë””ì˜¤ ê¸¸ì´


# =====================================================
# 1. STT (Speech-to-Text) - openai-whisper
# =====================================================
def transcribe_audio(
    audio_path: str,
    model_size: str = "small",
    language: str = "ko"
) -> Tuple[str, List[TextSegment]]:
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (openai-whisper)
    
    Args:
        audio_path: WAV/MP3 ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        model_size: ëª¨ë¸ í¬ê¸° (tiny, base, small, medium, large)
        language: ì–¸ì–´ ì½”ë“œ (ko=í•œêµ­ì–´, en=ì˜ì–´)
        
    Returns:
        (ì „ì²´ í…ìŠ¤íŠ¸, ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸)
    """
    if not WHISPER_AVAILABLE:
        print("[!] openai-whisperê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return "", []
    
    if not os.path.exists(audio_path):
        print(f"[!] ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")
        return "", []
    
    print(f"ğŸ“ [STT] Whisper ëª¨ë¸ ë¡œë”©... ({model_size})")
    
    # ëª¨ë¸ ë¡œë“œ
    model = whisper.load_model(model_size)
    
    print(f"   ì–¸ì–´: {language}")
    print(f"   ğŸ™ï¸ ìŒì„± ì¸ì‹ ì¤‘...")
    
    # ìŒì„± ì¸ì‹ ì‹¤í–‰
    result = model.transcribe(
        audio_path,
        language=language,
        verbose=False
    )
    
    segments = []
    for seg in result.get("segments", []):
        segment = TextSegment(
            start=seg["start"],
            end=seg["end"],
            text=seg["text"].strip()
        )
        segments.append(segment)
    
    full_text = result.get("text", "").strip()
    
    print(f"   âœ… STT ì™„ë£Œ: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸, {len(full_text)}ì")
    
    return full_text, segments


# =====================================================
# 2. êµìˆ˜ í™”ë²• ë¶„ì„ (ìˆ˜ì—… ì „ë‹¬)
# =====================================================
def analyze_teaching_speech(text: str) -> Dict:
    """
    êµìˆ˜ í™”ë²• ë¶„ì„
    
    ë¶„ì„ í•­ëª©:
    - ìš©ì–´ ì„¤ëª…: "~ë€", "~ì´ë€", "~ì˜ ì˜ë¯¸ëŠ”" ë“±
    - ì˜ˆì‹œ ì‚¬ìš©: "ì˜ˆë¥¼ ë“¤ì–´", "ì˜ˆì»¨ëŒ€" ë“±
    - ê°•ì¡° í‘œí˜„: "ì¤‘ìš”í•œ", "í•µì‹¬", "ë°˜ë“œì‹œ" ë“±
    """
    # ìš©ì–´ ì„¤ëª… íŒ¨í„´
    term_patterns = [
        r'[ê°€-í£]+[ì´]?ë€',           # ~ë€, ~ì´ë€
        r'ì˜\s*ì˜ë¯¸ëŠ”',                # ~ì˜ ì˜ë¯¸ëŠ”
        r'[ê°€-í£]+[ì„ë¥¼]\s*ë§[í•©í•˜]',  # ~ë¥¼ ë§í•©ë‹ˆë‹¤
        r'ì •ì˜[í•˜í•´]',                 # ì •ì˜í•˜ë©´, ì •ì˜í•´ë³´ë©´
        r'ëœ»[ì€ì´]',                   # ~ì˜ ëœ»ì€
    ]
    
    # ì˜ˆì‹œ ì‚¬ìš© íŒ¨í„´
    example_patterns = [
        r'ì˜ˆë¥¼\s*ë“¤[ì–´ë©´]',            # ì˜ˆë¥¼ ë“¤ì–´, ì˜ˆë¥¼ ë“¤ë©´
        r'ì˜ˆì»¨ëŒ€',
        r'[ì˜ˆì‚¬]ë¡€[ë¡œë¥¼]',             # ì˜ˆë¡œ, ì‚¬ë¡€ë¡œ
        r'ì˜ˆ[ì‹œì œ]',                   # ì˜ˆì‹œ, ì˜ˆì œ
        r'ê°€ë ¹',
        r'for\s*example',
        r'ì‹¤[ì œë¡€][ë¡œì˜]',             # ì‹¤ì œë¡œ, ì‹¤ë¡€ë¡œ
    ]
    
    # ê°•ì¡° í‘œí˜„ íŒ¨í„´
    emphasis_patterns = [
        r'ì¤‘ìš”[í•œí•©]',                 # ì¤‘ìš”í•œ, ì¤‘ìš”í•©ë‹ˆë‹¤
        r'í•µì‹¬[ì€ì ]?',                # í•µì‹¬, í•µì‹¬ì€, í•µì‹¬ì 
        r'ë°˜ë“œì‹œ',
        r'ê¼­',
        r'í•„ìˆ˜[ì ]?',
        r'ì ˆëŒ€[ë¡œ]?',
        r'íŠ¹[íˆë³„]',                   # íŠ¹íˆ, íŠ¹ë³„íˆ
        r'ì£¼[ëª©ì˜][í•˜í•´]',             # ì£¼ëª©í•˜ì„¸ìš”, ì£¼ì˜í•˜ì„¸ìš”
    ]
    
    # íŒ¨í„´ ë§¤ì¹­ ì¹´ìš´íŠ¸
    term_count = sum(len(re.findall(p, text, re.IGNORECASE)) for p in term_patterns)
    example_count = sum(len(re.findall(p, text, re.IGNORECASE)) for p in example_patterns)
    emphasis_count = sum(len(re.findall(p, text, re.IGNORECASE)) for p in emphasis_patterns)
    
    # ë‹¨ì–´ ìˆ˜ ê¸°ì¤€ ì •ê·œí™” (1000ë‹¨ì–´ë‹¹ ë¹ˆë„)
    word_count = len(text.split())
    normalize = lambda x: (x / max(1, word_count)) * 1000
    
    return {
        "term_explanation_count": term_count,
        "term_explanation_per_1000": round(normalize(term_count), 2),
        "example_usage_count": example_count,
        "example_usage_per_1000": round(normalize(example_count), 2),
        "emphasis_count": emphasis_count,
        "emphasis_per_1000": round(normalize(emphasis_count), 2),
        "teaching_speech_score": min(100, (term_count * 5 + example_count * 8 + emphasis_count * 3))
    }


# =====================================================
# 3. ìƒí˜¸ì‘ìš© ë¶„ì„ (í•™ìŠµì ì°¸ì—¬)
# =====================================================
def analyze_interaction(text: str) -> Dict:
    """
    ìƒí˜¸ì‘ìš©(í•™ìŠµì ì°¸ì—¬ ìœ ë„) ë¶„ì„
    
    ë¶„ì„ í•­ëª©:
    - ì§ˆë¬¸ ê¸°ë²•: ì˜ë¬¸ë¬¸ ì‚¬ìš©
    - ì°¸ì—¬ ìœ ë„: "ìƒê°í•´ë³´ì„¸ìš”", "í•´ë³¼ê¹Œìš”" ë“±
    """
    # ì§ˆë¬¸ íŒ¨í„´
    question_patterns = [
        r'[ê°€-í£]+[ê¹Œìš”][\?]?',        # ~í• ê¹Œìš”?, ~ì¼ê¹Œìš”?
        r'[ê°€-í£]+[ë‚˜ìš”][\?]?',        # ~í•˜ë‚˜ìš”?, ~ì¸ê°€ìš”?
        r'[ê°€-í£]+[ì„ê¹Œ][\?]?',        # ~ì¼ê¹Œ?, ~í• ê¹Œ?
        r'ì™œ[ì¼ìš”\s]',                 # ì™œ ~
        r'ì–´ë–»[ê²Œ]',                   # ì–´ë–»ê²Œ
        r'ë¬´ì—‡[ì„ì´]',                 # ë¬´ì—‡ì„, ë¬´ì—‡ì´
        r'ì–´[ë–¤ë””]',                   # ì–´ë–¤, ì–´ë””
        r'ëˆ„[ê°€êµ¬]',                   # ëˆ„ê°€, ëˆ„êµ¬
        r'ì–¸ì œ',
        r'\?',                         # ë¬¼ìŒí‘œ
    ]
    
    # ì°¸ì—¬ ìœ ë„ íŒ¨í„´
    participation_patterns = [
        r'ìƒê°[í•´ë³´]',                 # ìƒê°í•´ë³´ì„¸ìš”
        r'í•´[ë´ë³¼][ìš”ê¹Œ]',             # í•´ë´ìš”, í•´ë³¼ê¹Œìš”
        r'ì–´ë–¤ê°€ìš”',
        r'ì–´ë– [ì„¸ì‹ ]',                 # ì–´ë– ì„¸ìš”, ì–´ë– ì‹ ê°€ìš”
        r'ë– ì˜¬[ë ¤ë¼]',                 # ë– ì˜¬ë ¤ë³´ì„¸ìš”
        r'ìƒìƒ[í•´]',
        r'[í•¨ê»˜ê°™ì´]',                 # í•¨ê»˜, ê°™ì´
        r'ì§ì ‘',
        r'ì—¬ëŸ¬ë¶„[ì€ì´]?',
    ]
    
    question_count = sum(len(re.findall(p, text, re.IGNORECASE)) for p in question_patterns)
    participation_count = sum(len(re.findall(p, text, re.IGNORECASE)) for p in participation_patterns)
    
    word_count = len(text.split())
    normalize = lambda x: (x / max(1, word_count)) * 1000
    
    return {
        "question_count": question_count,
        "question_per_1000": round(normalize(question_count), 2),
        "participation_prompt_count": participation_count,
        "participation_per_1000": round(normalize(participation_count), 2),
        "interaction_score": min(100, (question_count * 3 + participation_count * 5))
    }


# =====================================================
# 4. êµ¬ì¡°í™” ë¶„ì„ (ìˆ˜ì—… ì„¤ê³„)
# =====================================================
def analyze_structure(text: str) -> Dict:
    """
    ìˆ˜ì—… êµ¬ì¡°í™” ë¶„ì„
    
    ë¶„ì„ í•­ëª©:
    - ë„ì…: í•™ìŠµ ëª©í‘œ, ì˜¤ëŠ˜, ì´ë²ˆ ì‹œê°„
    - ì „í™˜: ë‹¤ìŒìœ¼ë¡œ, ì´ì œ, ê·¸ëŸ¬ë©´
    - ìš”ì•½: ì •ë¦¬í•˜ë©´, í•µì‹¬ì€, ìš”ì•½
    """
    # ë„ì… íŒ¨í„´
    intro_patterns = [
        r'ì˜¤ëŠ˜ì€?',
        r'ì´ë²ˆ\s*ì‹œê°„',
        r'í•™ìŠµ\s*ëª©í‘œ',
        r'ëª©[í‘œì ]',
        r'ì‹œì‘[í•˜í•´]',
        r'ì‚´í´[ë³´ë³¼]',
        r'ì•Œì•„[ë³´ë³¼]',
    ]
    
    # ì „í™˜ íŒ¨í„´
    transition_patterns = [
        r'ë‹¤ìŒ[ìœ¼ë¡œ]?',
        r'ì´[ì œì  ]',
        r'ê·¸[ëŸ¬ë˜ëŸ¼]ë©´',
        r'ê·¸[ë¦¬ë˜]ê³ ',
        r'ë˜[í•œ]?',
        r'ë§ˆì°¬ê°€ì§€ë¡œ',
        r'í•œí¸',
        r'ë°˜[ë©´ëŒ€][ì—ë¡œ]?',
    ]
    
    # ìš”ì•½ íŒ¨í„´
    summary_patterns = [
        r'ì •ë¦¬[í•˜í•´]ë©´',
        r'ìš”ì•½[í•˜í•´]',
        r'í•µì‹¬ì€?',
        r'ê²°ë¡ [ì€ì ]?',
        r'ë§ˆë¬´ë¦¬',
        r'ì¢…í•©[í•˜í•´]',
        r'ë‹¤ì‹œ\s*ë§[í•´í•˜]',
        r'ê°„ë‹¨íˆ',
    ]
    
    intro_count = sum(len(re.findall(p, text, re.IGNORECASE)) for p in intro_patterns)
    transition_count = sum(len(re.findall(p, text, re.IGNORECASE)) for p in transition_patterns)
    summary_count = sum(len(re.findall(p, text, re.IGNORECASE)) for p in summary_patterns)
    
    word_count = len(text.split())
    normalize = lambda x: (x / max(1, word_count)) * 1000
    
    return {
        "intro_count": intro_count,
        "intro_per_1000": round(normalize(intro_count), 2),
        "transition_count": transition_count,
        "transition_per_1000": round(normalize(transition_count), 2),
        "summary_count": summary_count,
        "summary_per_1000": round(normalize(summary_count), 2),
        "structure_score": min(100, (intro_count * 3 + transition_count * 2 + summary_count * 5))
    }


# =====================================================
# 5. ì¢…í•© ë¶„ì„
# =====================================================
def analyze_text_track(
    audio_path: str,
    model_size: str = "small"
) -> Optional[TextAnalysisResult]:
    """
    ê°•ì˜ ì˜¤ë””ì˜¤ì˜ í…ìŠ¤íŠ¸ ì¢…í•© ë¶„ì„
    
    Args:
        audio_path: WAV ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        model_size: Whisper ëª¨ë¸ í¬ê¸°
        
    Returns:
        TextAnalysisResult ê°ì²´ (STT ì‹¤íŒ¨ ì‹œ None)
    """
    if not WHISPER_AVAILABLE:
        print("[!] faster-whisperê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ í…ìŠ¤íŠ¸ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    
    # STT ì‹¤í–‰
    full_text, segments = transcribe_audio(audio_path, model_size=model_size)
    
    if not full_text:
        print("[!] í…ìŠ¤íŠ¸ ë³€í™˜ ì‹¤íŒ¨")
        return None
    
    # ë¶„ì„ ì‹œê°„ ê³„ì‚°
    duration = segments[-1].end if segments else 0
    
    # ê°œë³„ ë¶„ì„ ìˆ˜í–‰
    teaching_metrics = analyze_teaching_speech(full_text)
    interaction_metrics = analyze_interaction(full_text)
    structure_metrics = analyze_structure(full_text)
    
    # ì¢…í•© ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
    quality_score = (
        teaching_metrics["teaching_speech_score"] * 0.4 +
        interaction_metrics["interaction_score"] * 0.35 +
        structure_metrics["structure_score"] * 0.25
    )
    
    word_count = len(full_text.split())
    
    print(f"\nğŸ“Š í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼:")
    print(f"   ë‹¨ì–´ ìˆ˜: {word_count}ê°œ")
    print(f"   êµìˆ˜ í™”ë²• ì ìˆ˜: {teaching_metrics['teaching_speech_score']}/100")
    print(f"   ìƒí˜¸ì‘ìš© ì ìˆ˜: {interaction_metrics['interaction_score']}/100")
    print(f"   êµ¬ì¡°í™” ì ìˆ˜: {structure_metrics['structure_score']}/100")
    print(f"   ğŸ“ ì¢…í•© ì ìˆ˜: {quality_score:.1f}/100")
    
    return TextAnalysisResult(
        transcript=full_text,
        segments=segments,
        teaching_metrics=teaching_metrics,
        interaction_metrics=interaction_metrics,
        structure_metrics=structure_metrics,
        quality_score=quality_score,
        word_count=word_count,
        duration_seconds=duration
    )


# =====================================================
# CLI í…ŒìŠ¤íŠ¸
# =====================================================
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        audio_file = sys.argv[1]
    else:
        audio_file = r"D:\data science\lecture_coach\output\ë…¹í™”_2025_02_21_08_37_50_910_audio.wav"
    
    if os.path.exists(audio_file):
        result = analyze_text_track(audio_file, model_size="small")
        if result:
            print(f"\nì „ì²´ í…ìŠ¤íŠ¸ (ì²« 500ì):")
            print(result.transcript[:500])
    else:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file}")
